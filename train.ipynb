{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c91c992c",
   "metadata": {},
   "source": [
    "The data set used for this project is a collection of sign language images anotated with bounding boxes around a letter in each picture.\n",
    "\n",
    "Link:\n",
    "https://public.roboflow.com/object-detection/american-sign-language-letters/1\n",
    "\n",
    "Below is getting the dataset and putting it into an S3 bucket for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b10c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data\n",
    "# %cd data\n",
    "# !curl -L \"https://public.roboflow.com/ds/uD9eURZZTd?key=ur-key-here\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9cb7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "# sagemaker.Session().upload_data(bucket='ur-bucket-name-here', path=\"data/\", key_prefix = \"data\n",
    "# !rm -rf data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e1bab",
   "metadata": {},
   "source": [
    "I will be using YOLOv7 in order to acheive real time inference. To do this I need to train a model with my custom dataset and store the model artifacts to S3. But first I need the YOLO repository. Either clone from down below or from the settings in the notebook creation wizard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17de03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed07bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.estimator import Estimator\n",
    "# from sagemaker import get_execution_role\n",
    "# from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# role = get_execution_role()\n",
    "# print(role)\n",
    "\n",
    "# estimator = Estimator(image_uri=\"gcp-training-container\",\n",
    "#                       role=role,\n",
    "#                       instance_count=1,\n",
    "#                       instance_type=\"local\",\n",
    "#                       output_path='s3://garagecamproject/output/',\n",
    "#                       base_job_name='gcp-train')\n",
    "\n",
    "# estimator.set_hyperparameters(\n",
    "#     weights = \"/opt/ml/code/base_weights.pt\",\n",
    "#     data = \"/opt/ml/input/data/training/data.yaml\",\n",
    "#     name = \"/opt/ml/model/trained_weights\",\n",
    "#     epochs = 5\n",
    "# )\n",
    "\n",
    "# estimator.fit(\n",
    "#     inputs=TrainingInput(\n",
    "#         s3_data=\"s3://garagecamproject/data\",\n",
    "#         input_mode='File'  # Available options: File | Pipe | FastFile\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1af860-0857-4c14-8c09-ffdd07981257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
